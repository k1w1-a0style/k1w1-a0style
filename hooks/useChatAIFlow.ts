import { useCallback, useEffect, useMemo, useRef, useState } from "react";
import { Alert } from "react-native";
import { v4 as uuidv4 } from "uuid";

import { ChatMessage, ProjectFile } from "../contexts/types";
import { runOrchestrator } from "../lib/orchestrator";
import { normalizeAiResponse } from "../lib/normalizer";
import { applyFilesToProject } from "../lib/fileWriter";
import {
  buildBuilderMessages,
  buildPlannerMessages,
  buildValidatorMessages,
} from "../lib/promptEngine";
import {
  looksLikeExplicitFileTask,
  looksLikeAdviceRequest,
  looksAmbiguousBuilderRequest,
  buildChangeDigest,
  buildExplainMessages,
} from "../utils/chatHeuristics";
import { handleMetaCommand } from "../utils/metaCommands";

export type PendingChange = {
  files: ProjectFile[];
  summary: string;
  created: string[];
  updated: string[];
  skipped: string[];
  aiResponse: any;
  agentResponse?: any;
};

export type PendingPlan = {
  originalRequest: string;
  planText: string;
  mode: "advice" | "build";
};

type ConfigLike = {
  selectedChatProvider: any;
  selectedChatMode: any;
  qualityMode: any;
  agentEnabled?: boolean;
  selectedAgentProvider?: any;
  selectedAgentMode?: any;
};

type AutoFixRequestLike = { message: string } | null;

type UseChatAIFlowArgs = {
  config: ConfigLike;
  messages: ChatMessage[];
  projectFiles: ProjectFile[];
  addChatMessage: (m: ChatMessage) => void;
  updateProjectFiles: (files: ProjectFile[]) => Promise<void>;
  autoFixRequest: AutoFixRequestLike;
  clearAutoFixRequest: () => void;

  hardScrollToBottom: (animated: boolean) => void;

  setIsStreaming: (v: boolean) => void;
  setStreamingMessage: React.Dispatch<React.SetStateAction<string>>;
  setIsAiLoading: (v: boolean) => void;
  setError: (v: string | null) => void;
  setShowConfirmModal: (v: boolean) => void;
};

export function useChatAIFlow({
  config,
  messages,
  projectFiles,
  addChatMessage,
  updateProjectFiles,
  autoFixRequest,
  clearAutoFixRequest,
  hardScrollToBottom,
  setIsStreaming,
  setStreamingMessage,
  setIsAiLoading,
  setError,
  setShowConfirmModal,
}: UseChatAIFlowArgs) {
  const [pendingPlan, setPendingPlan] = useState<PendingPlan | null>(null);
  const [pendingChange, setPendingChange] = useState<PendingChange | null>(
    null,
  );

  const isAtBottomRef = useRef(true);

  const inFlightRef = useRef(false);
  const isMountedRef = useRef(true);

  const streamingTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);

  // âœ… AutoFix: keine Busy-Wait Schleife mehr -> Queue + Drain
  const queuedAutoFixRef = useRef<string | null>(null);

  const safe = useCallback(<T>(fn: () => T): T | undefined => {
    if (!isMountedRef.current) return undefined;
    return fn();
  }, []);

  const setAtBottom = useCallback((v: boolean) => {
    isAtBottomRef.current = v;
  }, []);

  const cleanupStreamingTimer = useCallback(() => {
    if (streamingTimerRef.current) {
      clearTimeout(streamingTimerRef.current);
      streamingTimerRef.current = null;
    }
  }, []);

  useEffect(() => {
    return () => {
      isMountedRef.current = false;
      cleanupStreamingTimer();
      inFlightRef.current = false;
    };
  }, [cleanupStreamingTimer]);

  const simulateStreaming = useCallback(
    (fullText: string, onComplete: () => void) => {
      cleanupStreamingTimer();

      safe(() => setIsStreaming(true));
      safe(() => setStreamingMessage(""));

      let currentIndex = 0;
      const chunkSize = 12;
      const delay = 18;

      const tick = () => {
        if (!isMountedRef.current) return;

        if (currentIndex < fullText.length) {
          const nextChunk = fullText.slice(
            currentIndex,
            currentIndex + chunkSize,
          );
          currentIndex += chunkSize;

          safe(() => setStreamingMessage((prev) => prev + nextChunk));

          if (isAtBottomRef.current) {
            requestAnimationFrame(() => hardScrollToBottom(false));
          }

          streamingTimerRef.current = setTimeout(tick, delay);
          return;
        }

        cleanupStreamingTimer();
        safe(() => setIsStreaming(false));

        if (isAtBottomRef.current) {
          requestAnimationFrame(() => hardScrollToBottom(true));
        }

        onComplete();
      };

      streamingTimerRef.current = setTimeout(tick, delay);
    },
    [
      cleanupStreamingTimer,
      hardScrollToBottom,
      safe,
      setIsStreaming,
      setStreamingMessage,
    ],
  );

  const drainAutoFixQueue = useCallback(() => {
    if (inFlightRef.current) return;

    const msg = queuedAutoFixRef.current;
    if (!msg) return;

    queuedAutoFixRef.current = null;

    // AutoFix Message im Chat loggen
    addChatMessage({
      id: uuidv4(),
      role: "user",
      content: msg,
      timestamp: new Date().toISOString(),
      meta: { autoFix: true },
    });

    // Request starten (ohne Planner)
    void processAIRequest(msg, true, true);
  }, [addChatMessage]);

  // AutoFix kommt rein -> in Queue packen, clearen, drain versuchen
  useEffect(() => {
    const msg = autoFixRequest?.message;
    if (!msg) return;

    queuedAutoFixRef.current = msg;
    clearAutoFixRequest();
    drainAutoFixQueue();
  }, [autoFixRequest, clearAutoFixRequest, drainAutoFixQueue]);

  const processAIRequest = useCallback(
    async (userContent: string, isAutoFix = false, forceBuilder = false) => {
      if (inFlightRef.current) return;

      inFlightRef.current = true;
      safe(() => setIsAiLoading(true));
      safe(() => setError(null));

      try {
        const historyAsLlm = messages
          .map((m) => ({ role: m.role, content: m.content }))
          .filter((m) => String(m.content ?? "").trim().length > 0);

        // âœ… CALL 1: Planner (nur wenn nicht AutoFix / nicht forced / kein pendingPlan)
        if (!isAutoFix && !forceBuilder && !pendingPlan) {
          const advice = looksLikeAdviceRequest(userContent);
          const shouldPlanner =
            advice ||
            (looksAmbiguousBuilderRequest(userContent) &&
              !looksLikeExplicitFileTask(userContent));

          if (shouldPlanner) {
            const plannerMsgs = buildPlannerMessages(
              historyAsLlm,
              userContent,
              projectFiles,
            );

            const planRes = await runOrchestrator(
              config.selectedChatProvider,
              config.selectedChatMode,
              "speed",
              plannerMsgs,
            );

            if (
              planRes?.ok &&
              typeof planRes.text === "string" &&
              planRes.text.trim().length > 0
            ) {
              const planText = planRes.text.trim();

              addChatMessage({
                id: uuidv4(),
                role: "assistant",
                content:
                  "ðŸ§© **Kurz bevor ich Code anfasse:**\n\n" +
                  planText +
                  '\n\nâž¡ï¸ Antworte kurz auf die Fragen **oder** sag â€žweiter", dann starte ich den Build.',
                timestamp: new Date().toISOString(),
                meta: { planner: true },
              });

              safe(() =>
                setPendingPlan({
                  originalRequest: userContent,
                  planText,
                  mode: advice ? "advice" : "build",
                }),
              );

              return;
            }
          }
        }

        // âœ… CALL 2: Builder
        const llmMessages = buildBuilderMessages(
          historyAsLlm,
          userContent,
          projectFiles,
        );

        let ai = await runOrchestrator(
          config.selectedChatProvider,
          config.selectedChatMode,
          config.qualityMode,
          llmMessages,
        );

        if (!ai?.ok) {
          const errText = String((ai as any)?.error ?? "");
          const shouldRetry =
            /\b429\b|\brate\s*limit\b|\b503\b|overloaded|timeout|timed\s*out|ECONNRESET|network/i.test(
              errText,
            );
          if (shouldRetry) {
            ai = await runOrchestrator(
              config.selectedChatProvider,
              config.selectedChatMode,
              config.qualityMode,
              llmMessages,
            );
          }
        }

        if (!ai || !ai.ok) {
          const details =
            (ai as any)?.error ||
            (ai as any)?.errors?.join?.("\n") ||
            "Kein ok=true (unbekannter Fehler).";
          throw new Error(`KI-Request fehlgeschlagen: ${details}`);
        }

        const rawForNormalizer =
          (ai as any).files && Array.isArray((ai as any).files)
            ? (ai as any).files
            : (ai as any).text
              ? (ai as any).text
              : (ai as any).raw;

        const normalized = normalizeAiResponse(rawForNormalizer);
        if (!normalized) {
          const preview =
            typeof (ai as any).text === "string"
              ? String((ai as any).text)
                  .slice(0, 600)
                  .replace(/\s+/g, " ")
              : "";
          throw new Error(
            "Normalizer/Validator konnte die Dateien nicht verarbeiten." +
              (preview ? `\n\nOutput-Preview: ${preview}` : ""),
          );
        }

        // âœ… Optional Agent (Validator)
        let finalFiles = normalized;
        let agentMeta: any = null;

        if ((config as any)?.agentEnabled) {
          try {
            const validatorMsgs = buildValidatorMessages(
              userContent,
              normalized.map((f: any) => ({
                path: f.path,
                content: f.content,
              })),
              projectFiles,
            );

            const agentRes = await runOrchestrator(
              (config as any)?.selectedAgentProvider ??
                config.selectedChatProvider,
              (config as any)?.selectedAgentMode ?? config.selectedChatMode,
              "quality",
              validatorMsgs,
            );

            if (agentRes && agentRes.ok) {
              const agentRaw =
                (agentRes as any).files &&
                Array.isArray((agentRes as any).files)
                  ? (agentRes as any).files
                  : agentRes.text
                    ? agentRes.text
                    : (agentRes as any).raw;

              const normalizedAgent = normalizeAiResponse(agentRaw);
              if (normalizedAgent && normalizedAgent.length > 0) {
                finalFiles = normalizedAgent;
                agentMeta = agentRes;
              }
            }
          } catch {}
        }

        const mergeResult = applyFilesToProject(projectFiles, finalFiles);

        // âœ… Explain-Call
        let explainText = "";
        if (
          !isAutoFix &&
          mergeResult.created.length + mergeResult.updated.length > 0
        ) {
          try {
            const digest = buildChangeDigest(
              projectFiles,
              mergeResult.files,
              mergeResult.created,
              mergeResult.updated,
            );
            const explainMsgs = buildExplainMessages(userContent, digest);
            const explainRes = await runOrchestrator(
              config.selectedChatProvider,
              config.selectedChatMode,
              "speed",
              explainMsgs,
            );
            if (explainRes?.ok && typeof explainRes.text === "string") {
              explainText = explainRes.text.trim();
            }
          } catch {}
        }

        const prefix = isAutoFix
          ? "ðŸ¤– **Auto-Fix Vorschlag:**"
          : "ðŸ¤– Die KI mÃ¶chte folgende Ã„nderungen vornehmen:";

        const summaryText =
          `${prefix}\n\n` +
          (explainText
            ? `ðŸ§¾ **Kurz erklÃ¤rt (warum/was):**\n${explainText}\n\n---\n\n`
            : "") +
          `ðŸ“ **Neue Dateien** (${mergeResult.created.length}):\n` +
          (mergeResult.created.length
            ? mergeResult.created
                .slice(0, 6)
                .map((f) => `  â€¢ ${f}`)
                .join("\n") +
              (mergeResult.created.length > 6
                ? `\n  ... und ${mergeResult.created.length - 6} weitere`
                : "")
            : "  (keine)") +
          `\n\n` +
          `ðŸ“ **GeÃ¤nderte Dateien** (${mergeResult.updated.length}):\n` +
          (mergeResult.updated.length
            ? mergeResult.updated
                .slice(0, 6)
                .map((f) => `  â€¢ ${f}`)
                .join("\n") +
              (mergeResult.updated.length > 6
                ? `\n  ... und ${mergeResult.updated.length - 6} weitere`
                : "")
            : "  (keine)") +
          (!isAutoFix
            ? `\n\nâ­ **Ãœbersprungen** (${mergeResult.skipped.length}):\n` +
              (mergeResult.skipped.length
                ? mergeResult.skipped
                    .slice(0, 3)
                    .map((f) => `  â€¢ ${f}`)
                    .join("\n") +
                  (mergeResult.skipped.length > 3
                    ? `\n  ... und ${mergeResult.skipped.length - 3} weitere`
                    : "")
                : "  (keine)")
            : "") +
          `\n\nMÃ¶chtest du diese Ã„nderungen Ã¼bernehmen?`;

        simulateStreaming(summaryText, () => {
          safe(() =>
            setPendingChange({
              files: mergeResult.files,
              summary: summaryText,
              created: mergeResult.created,
              updated: mergeResult.updated,
              skipped: mergeResult.skipped,
              aiResponse: ai,
              agentResponse: agentMeta ?? undefined,
            }),
          );
          safe(() => setShowConfirmModal(true));
        });
      } catch (e: any) {
        const msg = `âš ï¸ ${e?.message || "Es ist ein Fehler im Builder-Flow aufgetreten."}`;
        safe(() => setError(msg));

        addChatMessage({
          id: uuidv4(),
          role: "assistant",
          content: msg,
          timestamp: new Date().toISOString(),
          meta: { error: true },
        });
      } finally {
        safe(() => setIsAiLoading(false));
        inFlightRef.current = false;

        // âœ… Wenn AutoFix queued ist: nach dem Call abarbeiten
        setTimeout(() => {
          if (isMountedRef.current) drainAutoFixQueue();
        }, 0);
      }
    },
    [
      addChatMessage,
      config,
      drainAutoFixQueue,
      messages,
      pendingPlan,
      projectFiles,
      safe,
      setError,
      setIsAiLoading,
      setShowConfirmModal,
      simulateStreaming,
    ],
  );

  const applyChanges = useCallback(async () => {
    if (!pendingChange) return;

    safe(() => setShowConfirmModal(false));

    try {
      await updateProjectFiles(pendingChange.files);

      const timing = pendingChange.aiResponse?.timing?.durationMs
        ? ` (${(pendingChange.aiResponse.timing.durationMs / 1000).toFixed(1)}s)`
        : "";

      const { created, updated, skipped } = pendingChange;

      const summaryText =
        `ðŸ¤– Provider: ${pendingChange.aiResponse?.provider || "unbekannt"}${
          pendingChange.aiResponse?.keysRotated
            ? ` (${pendingChange.aiResponse.keysRotated}x Key-Rotation)`
            : ""
        }\n` +
        `ðŸ†• Neue Dateien: ${created.length}\n` +
        `âœï¸ GeÃ¤nderte Dateien: ${updated.length}\n` +
        `â­ï¸ Ãœbersprungen: ${skipped.length}`;

      const lines: string[] = [];
      if (created.length) {
        lines.push("ðŸ†• Neue Dateien:");
        created.forEach((p) => lines.push(`  â€¢ ${p}`));
      }
      if (updated.length) {
        lines.push("âœï¸ GeÃ¤nderte Dateien:");
        updated.forEach((p) => lines.push(`  â€¢ ${p}`));
      }
      if (skipped.length) {
        lines.push("â­ï¸ Ãœbersprungene Dateien:");
        skipped.forEach((p) => lines.push(`  â€¢ ${p}`));
      }

      const filesBlock = lines.length
        ? `\n\nðŸ“‚ Details:\n${lines.join("\n")}`
        : "";
      const confirmationText = `âœ… Ã„nderungen erfolgreich angewendet${timing}\n\n${summaryText}${filesBlock}`;

      addChatMessage({
        id: uuidv4(),
        role: "assistant",
        content: confirmationText,
        timestamp: new Date().toISOString(),
        meta: { provider: pendingChange.aiResponse?.provider || "system" },
      });

      requestAnimationFrame(() => hardScrollToBottom(true));
    } catch (e: any) {
      Alert.alert(
        "Fehler beim Anwenden",
        e?.message || "Ã„nderungen konnten nicht angewendet werden.",
      );
      addChatMessage({
        id: uuidv4(),
        role: "system",
        content: `âš ï¸ Fehler beim Anwenden der Ã„nderungen: ${e?.message || "Unbekannt"}`,
        timestamp: new Date().toISOString(),
        meta: { error: true },
      });
    } finally {
      safe(() => setPendingChange(null));
    }
  }, [
    addChatMessage,
    hardScrollToBottom,
    pendingChange,
    safe,
    setShowConfirmModal,
    updateProjectFiles,
  ]);

  const rejectChanges = useCallback(() => {
    addChatMessage({
      id: uuidv4(),
      role: "system",
      content: "âŒ Ã„nderungen wurden abgelehnt. Keine Dateien wurden geÃ¤ndert.",
      timestamp: new Date().toISOString(),
    });
    safe(() => setShowConfirmModal(false));
    safe(() => setPendingChange(null));
  }, [addChatMessage, safe, setShowConfirmModal]);

  const handleSendWithMeta = useCallback(
    async (rawInput: string, selectedFileName?: string) => {
      const userContent =
        rawInput.trim() ||
        (selectedFileName ? `Datei gesendet: ${selectedFileName}` : "");

      if (!userContent.trim()) return;

      addChatMessage({
        id: uuidv4(),
        role: "user",
        content: userContent,
        timestamp: new Date().toISOString(),
      });

      const metaResult = handleMetaCommand(rawInput.trim(), projectFiles);
      if (metaResult.handled && metaResult.message) {
        addChatMessage(metaResult.message);
        return;
      }

      if (pendingPlan) {
        const lower = userContent.trim().toLowerCase();
        const wantsProceed =
          lower === "weiter" ||
          lower === "mach weiter" ||
          lower === "ok" ||
          lower === "ja" ||
          lower === "go";

        if (pendingPlan.mode === "advice" && !wantsProceed) {
          addChatMessage({
            id: uuidv4(),
            role: "assistant",
            content:
              'Alles klar. Wenn du willst, kann ich das direkt umsetzen â€“ sag einfach **â€žweiter"** oder nenn die Features.',
            timestamp: new Date().toISOString(),
          });
          return;
        }

        const combined =
          pendingPlan.originalRequest +
          "\n\n---\nPlaner-Ausgabe:\n" +
          pendingPlan.planText +
          "\n\n---\nNutzer-Antwort/Details:\n" +
          (wantsProceed ? "(User sagt: weiter)" : userContent);

        safe(() => setPendingPlan(null));
        await processAIRequest(combined, false, true);
        return;
      }

      await processAIRequest(userContent, false, false);
    },
    [addChatMessage, pendingPlan, processAIRequest, projectFiles, safe],
  );

  return useMemo(
    () => ({
      pendingPlan,
      pendingChange,
      isAtBottomRef,
      setAtBottom,
      handleSendWithMeta,
      applyChanges,
      rejectChanges,
    }),
    [
      applyChanges,
      handleSendWithMeta,
      pendingChange,
      pendingPlan,
      rejectChanges,
      setAtBottom,
    ],
  );
}
